{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf8ddb4-693b-428d-8ffa-4a6fc940cb6a",
   "metadata": {},
   "source": [
    "# Diffusion \"Self-guidance\"\n",
    "\n",
    "https://dave.ml/selfguidance/\n",
    "\n",
    "**Use-case:** Method to move/resize objects, replace objects with new ones, change scene backgrounds of diffusion generated images\n",
    "\n",
    "**Overview:**\n",
    "\n",
    "- uses the attention maps and activations to steer the image generation\n",
    "  - both are from the attention layers of the diffusion model<sup>1</sup>\n",
    "  - these allow us to figure out objects, object position/size...\n",
    "- using the above we figure out a value to add to the \"noise\" generated at each step of de-noising<sup>2</sup>\n",
    "  - since the noise is subtracted from the noisy image to produce a clearer image<sup>3</sup>\n",
    "  - this extra value effectively changes what the image produced will look like\n",
    "- math on the \"self-guidance\" <sup>4</sup>\n",
    "  - Object position: Computed as center of mass of relevant attention channels\n",
    "  - Object size: Spatial sum of thresholded attention channel\n",
    "  - Object shape: Thresholded attention map itself\n",
    "  - Object appearance: Combination of thresholded attention and spatial activation maps\n",
    "\n",
    "**Q's:**\n",
    "- what's an attention map? (medium- priority)\n",
    "  - perhaps do notes on the recurrent models chapter up to transformers to solidify the attention concept\n",
    "  - then get this attention map info if still needed\n",
    "- everything on the third bullet above object position..., no idea what any of those things mean. (medium priority)\n",
    "\n",
    "<sup><sub>Further contexts:</sub></sup>\n",
    "- <sup><sub>1. the original diffusion paper (Ho et al.) does not use attention layers, but the ones today (2024) do. ex. Stable Diffusion</sub></sup>\n",
    "- <sup><sub>2. if i forget this just skim the diffusion folder notes</sub></sup>\n",
    "- <sup><sub>3. not really \"clearer\" as in there's a final form for the noisy image thats the same all the time. i just mean getting closer to the formed image by removing a bit more noise.<sub></sup>\n",
    "- <sup><sub>4. i honestly have no idea what these things mean like \"center of mass\" of attention channels. i'm considering coming back to this after a firmer grasp on attention, then attention maps. And then see if i get closer to grokking this, since i need a better grasp on attention/recurrent nn fundamentals to advance on involving in ai research regardless of this paper <sub></sup>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6897ea-3cee-4264-b530-5e3bad1aa5b0",
   "metadata": {},
   "source": [
    "## Math of guiding image generation with \"self-guidance\"\n",
    "\n",
    "Typical diffusion:\n",
    "\n",
    "$$\n",
    "\\hat{\\epsilon}_t = (1 + s)\\epsilon_{\\theta}(z_t; t, y) - s\\epsilon_{\\theta}(z_t; t, \\emptyset)\n",
    "$$\n",
    "\n",
    "- $\\hat{\\epsilon}_t$ noise to be removed at step t\n",
    "- $z_t$ is the current noisy image\n",
    "- y is the conditioning (like a text prompt)\n",
    "- $\\emptyset$ is no conditioning (gen diffusion as if no text prompt is there<sup>1</sup>)\n",
    "- $\\epsilon_{\\theta}$ is the function to predict the noise\n",
    "  - $\\epsilon_{\\theta}(z_t; t, y)$ predicts the noise given the conditioning info (from text prompt)\n",
    "  - $\\epsilon_{\\theta}(z_t; t, \\emptyset)$ predicts the noise given no conditioning\n",
    "\n",
    "With self-guidance:\n",
    "\n",
    "$$\n",
    "\\hat{\\epsilon}_t = (1 + s)\\epsilon_{\\theta}(z_t; t, y) - s\\epsilon_{\\theta}(z_t; t, \\emptyset) + v\\sigma_t \\nabla_{z_t} g(z_t; t, y)\n",
    "$$\n",
    "\n",
    "- $v\\sigma_t \\nabla_{z_t} g(z_t; t, y)$ is the only thing thats different (added)\n",
    "  - calculating this value for each step allows for \"self-guidance\" (changing object size, position, etc)\n",
    "\n",
    "**Q's:**\n",
    "- why is the first question noise w/ text conditioning minus noise w/o text conditioning? (low+ priority)\n",
    "  - how subtracting nosie w/o text conditioning help with finding the correct noise amount to remove at that step?\n",
    "- in the first equation, why is the scalars (1+s) applied? (low- priority)\n",
    "- in the first equation, what exactly does the math function/equation for $epsilon_{\\theta}$ actually look like? (low+ priority)\n",
    "\n",
    "<sup><sub>Further contexts:</sub></sup>\n",
    "- <sup><sub>1. though doesn't quite mean \"empty\" string. perhaps digging into this will unveil what it is mathematically (low priority)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1bb349-5a24-4e02-a3d3-17c4a383a1f5",
   "metadata": {},
   "source": [
    "### Digging into the $v\\sigma_t \\nabla_{z_t} g(z_t; t, y)$ term\n",
    "\n",
    "$$v\\sigma_t \\nabla_{z_t} g(z_t; t, y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac154db-d00a-4533-aab0-c669cdb47250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1dec87-2be9-4ba4-93ab-30502d8277c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
