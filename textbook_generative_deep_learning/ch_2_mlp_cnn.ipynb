{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d47575e-59c7-4d4f-809c-36c5b038ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import datasets, utils, layers, models, optimizers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data() \n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Q: What's this do?\n",
    "# A: Each pixel is a 1-255 value (RGB). By dividing by 255, we scale these values to the range [0, 1]. \n",
    "#    This is a common preprocessing step since neural networks tend to perform better with input data that is on a smaller scale.\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0 \n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Q: What's this do?\n",
    "\"\"\"\n",
    "  A:\n",
    "The function utils.to_categorical is used to convert the class labels (which are integers) into a one-hot encoded format. \n",
    "\n",
    "Instead of representing the class as a single integer, it is represented as a binary vector that is all zeros except for the index of the class, which is marked with a one.\n",
    "\n",
    "For example, if we have 10 classes and a particular image belongs to class 2, the one-hot encoded label would be a vector where all elements are 0 except for the third element (since we start counting from 0), which would be 1.\n",
    "\n",
    "Let's say we have 10 classes, which means any given image can belong to one of these 10 classes, numbered from 0 to 9. If an image belongs to class 2, in one-hot encoding, we would represent this as a vector with 10 elements, where each element corresponds to a class. All elements will be set to 0, except for the one that corresponds to class 2, which will be set to 1.\n",
    "\n",
    "Classes:    0  1  2  3  4  5  6  7  8  9\n",
    "Vector:    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "y_train = utils.to_categorical(y_train, NUM_CLASSES) \n",
    "y_test = utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f91a6f6-72db-4fcc-a4aa-06bd56d33a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenli/Documents/github/steven4354/deep-learning-pytorch-book/myenv/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Q: What's a \"dense\" layer?\n",
    "# A: aka \"fully connected\" layer\n",
    "#    every neuron in this layer is connected to every neuron in the previous layer\n",
    "# \n",
    "#    equation:\n",
    "#    layer output = activation(W * input + b)\n",
    "#    \n",
    "#    where (W) is the weight matrix, b is the bias vector, activation is the activation function\n",
    "\n",
    "# Q: What's a \"flatten\" layer?\n",
    "# A: convert a multi-dimensional input into a one-dimensional array\n",
    "\n",
    "# Q: How large is the 1d array (vector) produced from \"flatten\"?\n",
    "# A: array size is 3,072 (= 32 × 32 × 3).\n",
    "\n",
    "# Q: What does a \"relu\" function look like?\n",
    "#         /\n",
    "# A: ____/\n",
    "#        0\n",
    "\n",
    "# Q: What does a \"softmax\" function look like?\n",
    "#            _____\n",
    "#           /\n",
    "#          /\n",
    "#         /\n",
    "# A: ____/\n",
    "#           0\n",
    "#   \"a gentle rise around zero\"\n",
    "#\n",
    "#   note: all activation functions are to introduce non linearity -> either/or case\n",
    "\n",
    "# Q: What does the 200, 150, 10 mean here?\n",
    "# A: The numbers 200, 150, and 10 refer to the number of neurons in the respective layers of the neural network defined in the code snippet.\n",
    "#    The last layer must have as many neurons as there are classes in the classification task, which is why it has 10 neurons in this case.\n",
    "# \n",
    "#    shape of our Input layer matches the shape of x_train and the shape of our Dense output layer matches the shape of y_train.\n",
    "\n",
    "# Q: Whats the 32, 32, 3?\n",
    "\"\"\"\n",
    "A: input_shape is the input of each item sent in for training. the shape 1 image. \n",
    "\n",
    "Here's a breakdown of the input shape:\n",
    "\n",
    "The first 32 refers to the height of the input images in pixels.\n",
    "The second 32 refers to the width of the input images in pixels.\n",
    "The 3 refers to the number of color channels in the input images. For RGB images, which are common in image processing, there are 3 channels representing red, green, and blue.\n",
    "\n",
    "cifar10 is a set of color images in 32x32 pixel size. \n",
    "\n",
    "also Flatten(input_shape=(32, 32, 3)) will also produce an \"input\" layer that takes in inputs of shape \"input_shape\", then this is fed into the Flatten layer to flatten into a 1D vector.\n",
    "\"\"\"\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(200, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(10, activation = 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd4425c-8dec-467c-b285-a4ab221d14e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,510</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m614,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │        \u001b[38;5;34m30,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,510\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">646,260</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m646,260\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">646,260</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m646,260\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Params is the number of weigths in each layer\n",
    "\n",
    "# Q: what happens if we remove one of the dense layers? will it still work? will it work better/worse?\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883b6d7d-4773-476e-8eda-6547938ada0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
